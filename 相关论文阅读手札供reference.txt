阅读手札

一、ACL OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews

1.结论：
(1)论文发现，通用型LLM不够严格，倾向于给出比人类评论更为积极的推荐。
(2)不旨在取代人工同行评审，但它为作者提供了一个在提交前获得快速、结构化反馈的宝贵工具
(3)评估表明，OpenReviewer的评审与人工评审员的判断非常接近，这表明它有可能帮助作者在写作过程中识别并解决其手稿中的弱点
2.语料：
(1)相反，我们希望帮助在预提交阶段面临挑战的作者。如果没有在提交前获得专家反馈，他们可能会忽略其手稿中的重大弱点或未能解决潜在审稿人的问题。这可能导致本可以通过早期反馈避免的不必要的拒稿或负面评审。
(2)现有模型往往难以生成符合学术同行评审所期望的深度、特定性、批判视角和结构的评论。通用的大规模语言模型可能会错过特定领域的惯例，无法恰当地评估技术贡献，或者提供的反馈不符合既定的评审实践。

3.可follow
(1)演示使用了Huggingface Spaces ZeroGPU硬件4，该硬件动态分配和释放GPU资源。虽然这使我们能够在特定的使用配额内免费托管演示，但它可能对其速度和响应性产生负面影响。然而，如果需要，用户可以随时在自己的硬件上克隆并运行该应用程序。
(2)我们通过下载最早可能的修订版来获取每篇论文的PDF格式。较晚的修订版通常是已经结合了评审反馈的最终版本，这使得至少部分评审内容变得无效。
(3)我们丢弃任何附录内容，只保留主体和参考部分的全文。我们按长度筛选论文和评论，移除顶部和底部1%分位数。
(4)收集了一个包含36K提交论文和141K评论的数据集，这些数据来自国际学习表征会议（ICLR）和神经信息处理系统会议（NeurIPS）
7)最后，我们只保留高置信度的评论。对于每个会议，我们选择一个大致等于“有信心，但不是绝对确定”的审稿人置信度阈值。过滤后，大约剩下79K条评论。
(5)OpenReviewer 使用了一个系统提示，该提示使LLM适应其评审者角色，并定义了一组受ICLR 2024评审者指南启发的固定评审指南。系统提示指定了评审必须以markdown格式书写并遵循特定的评审模板，该模板是输入的一部分并且在不同场合有所不同。用户提示非常简洁，仅包含“评审以下论文：”后跟完整的论文文本。