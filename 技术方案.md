# ScholarArena 技术方案（可落地版本）

> 面向 IJCAI 论文代码库的实现方案，目标是 **可复现、可评测、工程上可执行**。围绕“Foundry（离线技能炼制）+ Arena（在线受控交互）”闭环设计，保证策略输出具备可执行证据约束。

---

## 0. 项目目标与范围

**目标**：在多方文本交互（以同行评议为主）中学习“证据约束的策略言语行为”，输出结构化、可验证的行动指导，并在工具替换时保持高层策略可迁移。

**范围**：
- **主任务**：ICLR OpenReview 审稿/回复/元评审线程的 evidence-grounded 交互建模。
- **泛化验证**：通过替换工具库/证据原语验证策略迁移（不必更换任务语境）。
- **不做**：在线生成代码；不追求完全自动审稿；不依赖外部不可复现检索。

**核心产物**：
- 可复现的 **Foundry 数据炼制流水线**
- 可执行 **技能库（skills）+ 证据原语（primitives）**
- 受限执行的 **Arena 运行框架**
- 完整评测协议与基线实现

---

## 1. 关键对象与数据契约（工程可执行）

**Issue（争点单元）**
- 字段：`issue_id, type, severity, paper_span, grounding_ref, source_seg_ids, status, role`

**Intent（策略意图）**
- 10–15 个稳定类别（如 Challenge / Request-Evidence / Clarify / Concede / Summarize / Decide）

**Skill（技能）**
- 由 primitives 编排的 **确定性程序模板**，带清晰 I/O schema 与测试

**Evidence（观测）**
- 执行后返回的结构化结果（不可自由文本，必须可判定）

**Policy Action（行动指导）**
- 面向角色的结构化建议：
  - Reviewer：`claims + evidence + requested changes`
  - Author：`response strategy + required evidence/tasks`
  - AC/Editor：`issue summary + risk flags + decision suggestion`

---

## 2. 系统总体结构（Foundry + Arena）

```
                 ┌──────────────┐
   OpenReview →  │ Issue Mining │ → issue candidates
                 └──────┬───────┘
                        │
                 ┌──────▼───────┐
                 │ Ontology     │  (Intent/Evidence types)
                 └──────┬───────┘
                        │
                 ┌──────▼───────┐
                 │ Skill Foundry│  (compile + execute + filter)
                 └──────┬───────┘
                        │  golden trajectories
                 ┌──────▼───────┐
                 │  Training    │  (Plan-SFT / Act-SFT / DPO)
                 └──────┬───────┘
                        │
                 ┌──────▼───────┐
                 │   Arena      │  (plan → exec → update)
                 └──────────────┘
```

---

## 3. 数据与预处理流水线

### 3.1 输入数据结构（mining_results.jsonl）
- 数据来源：OpenReview 线程（review / rebuttal / meta-review / decision）+ 论文正文（PDF/LaTeX 本地存档）+ 弱标注 mining_results。  
- **一行一篇论文**，字段与示例一致：  
```json
{
  "forum_id": "GLWf2fq0bX",
  "title": "Skill Expansion and Composition in Parameter Space",
  "timestamp": 1765636813.92774,
  "analysis": {
    "mining_results": [
      {
        "source_seg_ids": ["7vTPFp2uOB_sum_0"],
        "role": "Reviewer",
        "grounding_ref": "Abstract, Sec 3.2, Sec 3.3",
        "cognitive_chain": "...",
        "latent_tool_calls": [
          {"tool_category": "Cognitive_Synthesis", "operation": "Summarize_Proposed_Framework", "target_type": "PSEC_Framework", "outcome": "..."}
        ],
        "strategic_intent": "Establish_Baseline_Understanding",
        "action": "..."
      }
    ]
  }
}
```
- `cognitive_chain` 仅作审计/分析元数据，不进入训练输入或标签。  

### 3.2 规范化记录（issue-level）
将 `analysis.mining_results` 展平为可直接处理的 issue 记录：  
```json
{
  "act_id": "GLWf2fq0bX#0003",
  "issue_id": "GLWf2fq0bX#0003",
  "forum_id": "GLWf2fq0bX",
  "title": "...",
  "timestamp": 1765636813.92774,
  "role": "Reviewer",
  "source_seg_ids": ["7vTPFp2uOB_wea_0"],
  "grounding_ref": "Related Works",
  "paper_span": null,
  "strategic_intent": "Expose_Methodological_Weakness",
  "intent": "Expose_Methodological_Weakness",
  "action": "Question the novelty of ...",
  "act_text": "Question the novelty of ...",
  "latent_tool_calls": [
    {"tool_category": "Literature_Cross_Check", "operation": "Compare_with_Prior_Art", "target_type": "PSEC_vs_Prior_Work", "outcome": "..."}
  ],
  "issue_type": null,
  "issue_cluster_id": null,
  "meta": {"cognitive_chain": "..."}
}
```

**输出**：`data/interim/mining_flat.jsonl`

### 3.3 预处理步骤（可复现）
1. **展平与对齐**：展开 `mining_results`，生成 `act_id/issue_id`，保留语义 act 所需的 `role/grounding_ref/strategic_intent/action/latent_tool_calls`。  
2. **grounding_ref → paper_span**：将 `grounding_ref` 解析为段落/页码/公式索引（失败则保留原值）。  
3. **语义 act 聚类**：  
   - 向量：`strategic_intent ⊕ action ⊕ (tool_category ⊕ operation ⊕ target_type ⊕ outcome)`（可选附加 `grounding_ref`）  
   - 聚类：HDBSCAN（主）+ KMeans（对照）  
4. **Teacher LLM 轻量标注（可选）**：  
   - 给 `issue_cluster_id` 赋 `issue_type/definition`  
   - 将原始 `strategic_intent` 映射到更小的 `intent_ontology`  
5. **Issue 线程化**：按 `(forum_id, issue_ontology_id)` 聚合为 `thread_id`（issue_ontology_id = issue_type 若有，否则回退到 issue_cluster_id）。  

**输出**：  
- `data/interim/grounded_issues.jsonl`  
- `data/processed/issues.jsonl`

---

## 4. Skill Foundry（离线炼制）

### 4.1 Executability Criterion（可执行判定）
一个条目只有在满足以下条件时才被视为 tool/primitive：
- **确定性 I/O**
- **可在给定 paper artifact 上执行**
- **输出结构化 evidence schema**
否则归入 Intent 或 ReviewAct。

### 4.2 Evidence Primitives（10–20 个确定性原语）
- 文档定位：`extract_span`, `extract_equation`, `extract_table`, `figure_crop`
- 引用解析：`resolve_citation`, `local_scholar_search`
- 统计检验：`t_test`, `bootstrap_ci`, `effect_size`
- 符号校验：`sympy_simplify`, `dimensional_check`
- 代码执行：`sandbox_run`（超时/资源限制）

### 4.3 Skill 编译（离线）
**Skill = primitives 编排模板**，输出三件套：
- `skill.py`：实现
- `skill.json`：参数与 evidence schema
- `tests/`：可执行最小测试（失败即丢弃）

Teacher LLM 仅用于 **Skill Compiler**，在线不参与决策。

### 4.4 Execution-Feedback Curation（核心闭环）
对每条弱标注样本：
1. 定位 `paper_span`
2. 选择技能并执行，得到 observation
3. 用 **predicate-first** 判定是否支持 intent
4. 通过则写入黄金轨迹：
   `(state, intent, tool_plan, observation, action_guidance)`

**输出**：`data/processed/trajectories.jsonl`

### 4.5 Foundry 脚本清单与接口（可直接实现）
1. `foundry/issue_mining/parse_mining_results.py`：展平 `analysis.mining_results` 为语义 act 记录。输入 `data/raw/mining_results.jsonl`，输出 `data/interim/mining_flat.jsonl`。  
```bash
python foundry/issue_mining/parse_mining_results.py --in data/raw/mining_results.jsonl --out data/interim/mining_flat.jsonl
```
2. `foundry/issue_mining/link_grounding_ref.py`：将 `grounding_ref` 解析到 paper span。输入 `data/interim/mining_flat.jsonl` 与 MinerU 转换的论文 Markdown，输出 `data/interim/grounded_issues.jsonl`。  
```bash
python foundry/issue_mining/link_grounding_ref.py --in data/interim/mining_flat.jsonl --papers data/raw/papers_md --out data/interim/grounded_issues.jsonl
```
3. `foundry/issue_mining/cluster_issues.py`：基于 embedding 聚类生成 `issue_cluster_id`。输入 `data/interim/grounded_issues.jsonl` + `data/raw/embeddings.npy`，输出 `data/processed/issues.jsonl`。  
```bash
python foundry/issue_mining/cluster_issues.py --in data/interim/grounded_issues.jsonl --embeddings data/raw/embeddings.npy --embed-input-mode semantic_act --out data/processed/issues.jsonl
```
4. `foundry/ontology/label_clusters.py`（可选）：teacher LLM 给 `issue_cluster_id` 赋 `issue_type/definition`。  
```bash
python foundry/ontology/label_clusters.py --in data/processed/issues.jsonl --out foundry/ontology/cluster_labels.jsonl
```
5. `foundry/ontology/label_intents.py`（可选）：将原始 `strategic_intent` 映射到稳定 intent 体系。  
```bash
python foundry/ontology/label_intents.py --in data/processed/issues.jsonl --out foundry/ontology/intent_map.json
```
6. `foundry/ontology/label_evidence_types.py`（可选）：teacher LLM 将 tool_category 映射到 evidence types。  
```bash
python foundry/ontology/label_evidence_types.py --in data/processed/issues.jsonl --out foundry/ontology/evidence_map.json --category-fallback
```
7. `foundry/issue_mining/build_issue_threads.py`：按 issue ontology 生成 `thread_id` 与索引（默认 `thread-by=ontology`）。输入 `data/processed/issues.jsonl`，输出 `data/processed/threads.jsonl` + `data/processed/thread_index.jsonl`。  
```bash
python foundry/issue_mining/build_issue_threads.py --in data/processed/issues.jsonl --labels foundry/ontology/cluster_labels.jsonl --out-threads data/processed/threads.jsonl --out-index data/processed/thread_index.jsonl
```
8. `foundry/ontology/build_ontology.py`：基于聚类与映射结果生成 intent/evidence/issue 类型表。输入 `data/processed/issues.jsonl`，输出 `foundry/ontology/*.json`。  
```bash
python foundry/ontology/build_ontology.py --in data/processed/issues.jsonl --out foundry/ontology --labels foundry/ontology/cluster_labels.jsonl --intent-map foundry/ontology/intent_map.json --evidence-map foundry/ontology/evidence_map.json
```
9. `foundry/curation/discover_primitives.py`：聚类 `latent_tool_calls` 并生成可执行原语清单。输入 `data/processed/issues.jsonl`，输出 `skills/primitives/registry.json`。  
```bash
python foundry/curation/discover_primitives.py --in data/processed/issues.jsonl --out skills/primitives/registry.json --method auto --write-stubs --evidence-map foundry/ontology/evidence_map.json
```
10. `foundry/curation/compile_skills.py`：将 primitives 编译为 skills，并更新 `skills/registry.json`。输入 `skills/primitives/registry.json`，输出 `skills/library/*`。  
```bash
python foundry/curation/compile_skills.py --primitives skills/primitives/registry.json --skills-dir skills/library --registry skills/registry.json
```
11. `foundry/curation/run_skills.py`：对 issue 执行技能，产出结构化 obs。输入 `data/processed/issues.jsonl` + `skills/registry.json`，输出 `data/interim/observations.jsonl`。  
```bash
python foundry/curation/run_skills.py --issues data/processed/issues.jsonl --registry skills/registry.json --out data/interim/observations.jsonl
```
12. `foundry/curation/curate_trajectories.py`：predicate 过滤并生成黄金轨迹。输入 `data/processed/issues.jsonl` + `data/interim/observations.jsonl`，输出 `data/processed/trajectories.jsonl`。  
```bash
python foundry/curation/curate_trajectories.py --issues data/processed/issues.jsonl --obs data/interim/observations.jsonl --thread-index data/processed/thread_index.jsonl --out data/processed/trajectories.jsonl
```

### 4.6 Foundry 核心接口（JSON）
**Primitive**（聚类后的可执行原语）：  
```json
{
  "primitive_id": "prim_0162_compare_with_prior_art",
  "tool_category": "Literature_Cross_Check",
  "operation": "Compare_with_Prior_Art",
  "target_type": "PSEC_vs_Prior_Work",
  "evidence_type": "Citation",
  "signature": {"paper_span": "SpanRef", "query": "string"},
  "evidence_schema": {"matches": "list", "missing_refs": "list"}
}
```

**PrimitiveAssignment**（tool-call → primitive 对齐）：  
```json
{
  "issue_id": "GLWf2fq0bX#0003",
  "call_index": 0,
  "primitive_id": "prim_0162_compare_with_prior_art",
  "cluster_id": "prim_cluster_0162"
}
```

**SkillManifest**（`skills/registry.json` 里的条目）：  
```json
{
  "skill_id": "compare_prior_art_v1",
  "name": "compare_prior_art",
  "definition": "Compare the cited method with prior art in related work.",
  "signature": {"paper_span": "SpanRef", "query": "string"},
  "evidence_schema": {"matches": "list", "missing_refs": "list"},
  "evidence_type": "Citation",
  "failure_codes": ["NO_SPAN", "NO_INDEX"],
  "entrypoint": "skills/library/compare_prior_art/skill.py:run",
  "source": {"primitive_id": "prim_0162_compare_with_prior_art"}
}
```

**TrajectoryRecord**（训练样本）：  
```json
{
  "issue_id": "GLWf2fq0bX#0003",
  "thread_id": "th_7b6c9d2f3a1b",
  "issue_cluster_id": "issue_0162",
  "state": {"role": "Reviewer", "paper_span": "...", "issue_state": "Open"},
  "intent": "Expose_Methodological_Weakness",
  "tool_plan": [{"tool": "compare_prior_art", "args": {"paper_span": "...", "query": "LoRA multi-task"}}],
  "observation": [{"tool": "compare_prior_art", "status": "ok", "payload": {"matches": ["[1]", "[2]"]}}],
  "action_guidance": "Question the novelty ...",
  "labels": {"support": "inconclusive"}
}
```

---

## 5. Arena（在线受控交互）

### 5.1 状态与动作
**状态**：`(role, paper_span, dialogue_summary, issue_state)`
**动作**：`(intent, tool_plan)`

### 5.2 Tool-Plan 结构（JSON Schema）
```json
{
  "intent": "Request-Evidence",
  "tool_plan": [
    {"tool": "extract_table", "args": {"table_id": "Table 2"}},
    {"tool": "effect_size", "args": {"table": "Table 2", "metric": "Acc"}}
  ]
}
```

### 5.3 Execution Controller（确定性组件）
- 校验 plan 合法性（schema/权限/资源）
- 调度 skill 执行与超时
- 返回 observation + failure code
- 记录可复现日志

### 5.4 Issue FSM（线性可复现）
`Open → EvidenceRequested → EvidenceCollected → (Supported | Refuted | Inconclusive) → Closed`

K 回合建议 2–3；若证据无增量则 Inconclusive。

### 5.5 Arena 脚本清单与接口（可直接实现）
1. `arena/controller/run_arena.py`：驱动单篇论文或单 issue 的交互流程。输入 `data/processed/issues.jsonl` 与 `skills/registry.json`，输出 `logs/arena/*.jsonl`。  
```bash
python arena/controller/run_arena.py --issues data/processed/issues.jsonl --registry skills/registry.json --out logs/arena
```
2. `arena/controller/validate_plan.py`：校验 LLM 输出的 plan 是否符合 schema（只允许 registry 中的工具）。输入 `tool_plan.json`，输出 `validated_plan.json` 或失败码。  
```bash
python arena/controller/validate_plan.py --plan tool_plan.json --registry skills/registry.json --out validated_plan.json
```
3. `arena/controller/execute_plan.py`：执行计划并返回 obs。输入 `validated_plan.json`，输出 `observation.json`。  
```bash
python arena/controller/execute_plan.py --plan validated_plan.json --out observation.json
```
4. `arena/state/update_fsm.py`：基于 obs 与动作更新 issue 状态。输入 `issue_state.json` + `observation.json`，输出 `issue_state.json`。  
```bash
python arena/state/update_fsm.py --state issue_state.json --obs observation.json --out issue_state.json
```
5. `arena/state/ledger_io.py`：读写 ledger 与事件日志，保证可复现。输入 `logs/arena/*.jsonl`，输出 `data/processed/ledger.jsonl`。  
```bash
python arena/state/ledger_io.py --events logs/arena --out data/processed/ledger.jsonl
```

### 5.6 Arena 核心接口（JSON）
**ToolPlan**（LLM 输出，执行前校验）：  
```json
{
  "intent": "Request-Evidence",
  "tool_plan": [
    {"call_id": "c1", "tool": "extract_table", "args": {"table_id": "Table 2"}, "depends_on": []},
    {"call_id": "c2", "tool": "effect_size", "args": {"table": "Table 2", "metric": "Acc"}, "depends_on": ["c1"]}
  ]
}
```

**Observation**（执行结果）：  
```json
{
  "issue_id": "GLWf2fq0bX#0003",
  "results": [
    {"call_id": "c1", "tool": "extract_table", "status": "ok", "payload": {"rows": 12}},
    {"call_id": "c2", "tool": "effect_size", "status": "ok", "payload": {"effect_size": 0.31}}
  ],
  "failure_codes": []
}
```

**PolicyAction**（输出给人类的行动指导）：  
```json
{
  "role": "Reviewer",
  "issue_id": "GLWf2fq0bX#0003",
  "claims": ["Novelty is unclear versus prior LoRA multi-task work."],
  "requested_changes": ["Add explicit comparison to [1,2]."],
  "evidence_refs": ["compare_prior_art_v1:matches=[1,2]"]
}
```

---

## 6. 训练方案

### 6.1 SFT 主线
- **Plan-SFT**：`state → (intent, tool_plan)`
- **Act-SFT**：`(state, observation) → action_guidance`
  监督信号来自 `trajectories.jsonl`：`intent` 由 `strategic_intent` 过滤映射，`action_guidance` 对应原始 `action`（经格式化），`tool_plan` 来自可执行 skills 编译结果。

### 6.2 可选 DPO/偏好优化
- 偏好构造：证据质量更高、unsupported claims 更少、关键争点解决度更高
- 目标：提升 action guidance 的可用性与证据一致性

---

## 7. 评测协议（与 T1/T2/T3 对齐）

### 7.1 指标
- Unsupported-Claim Rate
- Evidence Precision / Coverage
- Claim–Observation Consistency
- Decision Consistency（与真实 meta-review/decision）
- Token/Time Cost
- Robustness under injection

### 7.2 基线
- LLM-only
- RAG-only
- Tool-use naive（无 Foundry 过滤/无 ledger）
- ScholarArena（完整方案）

### 7.3 泛化实验
- 仅替换工具库/证据原语，比较 intent policy drop

---

## 8. 工程与可复现要求

- **固定随机种子**与 deterministic tools
- **本地索引**替代线上检索
- **数据版本化**：raw / processed / splits
- **日志与产物**：每轮保存 plan、obs、状态转移
- **最小测试**：skills 测试 + pipeline smoke test

---

## 9. 风险点与规避

- **伪工具混入** → Executability Criterion + tests
- **Prompt injection** → 只接收结构化计划；严格 schema
- **弱标注噪声** → Execution-Feedback Curation 丢弃不一致样本
- **跨工具库退化** → Intent–Skill 因子分解

---

## 10. 里程碑（可与排期对齐）

1. **Week 1**：Issue mining + ontology 初版
2. **Week 2**：primitives 实现 + skill 编译 + tests
3. **Week 3**：Foundry 闭环 + 产出 trajectories
4. **Week 4**：Plan-SFT/Act-SFT + baseline
5. **Week 5**：评测协议 + 消融/鲁棒实验

---

# 附：推荐项目目录（与实现对齐）

```
manuscript/
├─ FormattingGuidelines-IJCAI-ECAI-26/   # 官方 LaTeX 模板
├─ paper/                                # 论文工作区（可从模板复制）
├─ 技术方案.md
├─ docs/
├─ data/
│  ├─ raw/
│  ├─ interim/
│  ├─ processed/
│  ├─ splits/
│  └─ indices/
├─ foundry/
│  ├─ issue_mining/
│  ├─ ontology/
│  ├─ curation/
│  └─ outputs/
├─ skills/
│  ├─ primitives/
│  ├─ library/
│  ├─ tests/
│  └─ registry.json
├─ arena/
│  ├─ controller/
│  ├─ state/
│  └─ policies/
├─ configs/
├─ scripts/
├─ experiments/
├─ models/
├─ logs/
└─ tests/
```
